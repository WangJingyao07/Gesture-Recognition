# the body parts are swapped so that the left is always on the left
import pandas as pd
import numpy as np
import cv2, os
from scipy import signal
import csv

input_source = "hand.mp4"
cap = cv2.VideoCapture(input_source)
frame_number = 0
font, scale, colorText, thick = cv2.FONT_HERSHEY_SIMPLEX, .5, (234, 234, 234), 1
size, color, thickness = 5, (255, 255, 255), 5
window_length, polyorder = 13, 2
# get pose data - data is generated by open pose video
df = pd.read_csv('HandData_byWJY.csv')

POSE_PAIRS = [ [0,1],[1,2],[2,3],[3,4],[0,5],[5,6],[6,7],[7,8],[0,9],[9,10],[10,11],[11,12],[0,13],[13,14],[14,15],[15,16],[0,17],[17,18],[18,19],[19,20] ]
threshold = 0.2

# there are 21 points in the skeleton
# 0 手掌和腕部相接处
# 1,2,3,4 大拇指从下到上（手掌，二指节，一指节，指尖）
# 5.6.7.8 食指
# 9，10,11,12 中指
# 13，14,15,16 无名指
# 17，18,19,20, 小拇指

# 移动平均法（Moving average，MA）进行数据平滑
# 加权移动平均
for i in range(43): df[str(i)] = signal.savgol_filter(df[str(i)], window_length, polyorder)
# 简单移动平均

# ---------------------------------------------------------------
data = []
while cv2.waitKey(10) < 0 and frame_number < len(df.values) - 2:
    ret, img = cap.read()
    if not ret: break
    try:
        values = df.values[frame_number]
    except:
        break
    values = np.array(values, int)
    points = []
    points.append((values[0], values[22]))
    points.append((values[1], values[23]))
    points.append((values[2], values[24]))
    points.append((values[3], values[25]))
    points.append((values[4], values[26]))
    points.append((values[5], values[27]))
    points.append((values[6], values[28]))
    points.append((values[7], values[29]))
    points.append((values[8], values[30]))
    points.append((values[9], values[31]))
    points.append((values[10], values[32]))
    points.append((values[11], values[33]))
    points.append((values[12], values[34]))
    points.append((values[13], values[35]))
    points.append((values[14], values[36]))
    points.append((values[15], values[37]))
    points.append((values[16], values[38]))
    points.append((values[17], values[39]))
    points.append((values[18], values[40]))
    points.append((values[19], values[41]))
    points.append((values[20], values[42]))
    # points.append((values[21], values[43]))



    for pair in POSE_PAIRS:
        partA = pair[0]
        partB = pair[1]

        # for i in range(43): partA[str(i)] = signal.savgol_filter(partA[str(i)], window_length, polyorder)
        # for i in range(43): partB[str(i)] = signal.savgol_filter(partB[str(i)], window_length, polyorder)

        if points[partA] and points[partB]:
            cv2.line(img, points[partA], points[partB], (0, 255, 255), 2, lineType=cv2.LINE_AA)
            cv2.circle(img, points[partA], 5, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)
            cv2.circle(img, points[partB], 5, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)

    cv2.imshow('Output-Skeleton', img)
    frame_number += 1
cv2.destroyAllWindows()
